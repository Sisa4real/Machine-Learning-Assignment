{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Study the solvers**\n",
    "\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "In this lesson you learned about the various solvers that pair algorithms with a machine learning process to create an accurate model. Walk through the solvers listed in the lesson and pick two. In your own words, compare and contrast these two solvers. What kind of problem do they address? How do they work with various data structures? Why would you pick one over another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of classification algorithms, the term \"solver\" refers to a parameter used to optimize the model's parameters. Different algorithms may have different solver options available. Let's explore the commonly used solvers:\n",
    "\n",
    "1) Newton-Conjugate-Gradient ('newton-cg'):\n",
    "The 'newton-cg' solver combines Newton's method with conjugate gradient descent. It utilizes second-order derivative information (Hessian matrix) to find the optimal solution. This solver is suitable for binary and multiclass classification problems and can handle L2 and L2 penalty (regularization). It performs well when the number of features is not too large.\n",
    "\n",
    "2) Limited-memory Broyden-Fletcher-Goldfarb-Shanno ('lbfgs'):\n",
    "The 'lbfgs' solver is an optimization algorithm based on the BFGS method. It approximates the inverse Hessian matrix using limited memory. 'lbfgs' is efficient for large-scale problems and can handle L2 and L2 penalty (regularization). It is suitable for binary and multiclass classification problems.\n",
    "\n",
    "3) Library for Large Linear Classification ('liblinear'):\n",
    "The 'liblinear' solver is primarily used for linear support vector machines (SVM) and logistic regression. It employs a coordinate descent algorithm with linear time complexity. 'liblinear' is efficient for small-to-medium-sized datasets with a large number of samples. It supports L1 and L2 penalty (regularization) and can handle both binary and multiclass classification problems.\n",
    "\n",
    "4) Stochastic Average Gradient ('sag'):\n",
    "The 'sag' solver is designed for large-scale problems and is used in linear SVM and logistic regression. It utilizes a stochastic gradient descent algorithm with an average of gradients. 'sag' is efficient for datasets with a large number of samples and features. It supports L2 penalty (regularization) and can handle binary classification problems and multiclass classification with the one-vs-rest approach.\n",
    "\n",
    "5) Stochastic Average Gradient Adaptive ('saga'):\n",
    "The 'saga' solver is an extension of the 'sag' solver and is used in linear SVM and logistic regression. It includes the ability to handle both L1 and L2 penalties (regularization). 'saga' is particularly well-suited for large-scale problems with a large number of samples and features. It supports binary classification problems as well as multiclass classification using the one-vs-rest approach.\n",
    "\n",
    "    These solvers provide different optimization approaches and are selected based on the problem characteristics, dataset size, and computational efficiency requirements. The choice of solver can impact the training time, convergence, and overall performance of the classification model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
